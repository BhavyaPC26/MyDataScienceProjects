# -*- coding: utf-8 -*-
"""Fruad_detection_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xN-rjRy3qEmwUbg-nh2ZdJyhPIO1z6w_
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
from sklearn.model_selection import GridSearchCV

from google.colab import files
uploaded = files.upload()

df = pd.read_csv("fraud_detection.csv")
df

df.info()

df.duplicated().sum()

df.isnull().sum()/len(df)*100

df['Amount'].fillna(df['Amount'].mean(), inplace=True)

df.isnull().sum()/len(df)*100

df.describe()

plt.figure(figsize=(4,4))
plt.hist(df['TransactionType'], bins=30, color='skyblue', edgecolor='black')
plt.title(f'Distribution of TransactionType')
plt.xlabel('TransactionType')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()

sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

X = df.drop(columns=['Fraud','TransactionID','CustomerID'])
y = df['Fraud']

categorical_features = ['TransactionType', 'Location', 'DeviceType', 'TimeOfDay']
numerical_features = ['Amount', 'TransactionSpeed', 'PreviousFraud']
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_features),  # Scale numerical features
        ('cat', OneHotEncoder(), categorical_features)   # One-hot encode categorical features
    ])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

def evaluate_model(model, X_train, X_test, y_train, y_test):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    print(f"Classification Report:\n {classification_report(y_test, y_pred)}")
    print(f"Confusion Matrix:\n {confusion_matrix(y_test, y_pred)}")
    print(f"ROC AUC Score: {roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])}\n")

models = {
    'Logistic Regression': Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', LogisticRegression(random_state=42))
    ]),

    'Decision Tree': Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', DecisionTreeClassifier(random_state=42))
    ]),

    'Random Forest': Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', RandomForestClassifier(random_state=42))
    ]),

    'Gradient Boosting': Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', GradientBoostingClassifier(random_state=42))
    ]),

    'SVM': Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', SVC(probability=True, random_state=42))
    ]),

    'KNN': Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', KNeighborsClassifier())
    ])
}

# Evaluate each model
for model_name, model in models.items():
    print(f"Evaluating {model_name}...")
    evaluate_model(model, X_train, X_test, y_train, y_test)

param_grid = {
    'classifier__n_estimators': [100, 200],
    'classifier__max_depth': [None, 10, 20],
    'classifier__min_samples_split': [2, 5]
}
grid_search_rf = GridSearchCV(models['Random Forest'], param_grid, cv=5, n_jobs=-1, scoring='roc_auc')
grid_search_rf.fit(X_train, y_train)

# Best parameters from grid search for Random Forest
print("Best Parameters for Random Forest:", grid_search_rf.best_params_)
y_pred_rf = grid_search_rf.best_estimator_.predict(X_test)
print("Classification Report (Best Random Forest Model):\n", classification_report(y_test, y_pred_rf))
print("ROC AUC Score (Best Random Forest Model):", roc_auc_score(y_test, grid_search_rf.best_estimator_.predict_proba(X_test)[:, 1]))